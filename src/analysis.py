import math
import os
import pickle
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt
from matplotlib import font_manager, rcParams  # font handling for thesis
import ot
import ot.plot
import optuna
from pprint import pp
import yaml

import optimal_transport as solver
import util


## Set font properties for matplotlib
# rcParams['font.family'] = 'DejaVu Serif'
# rcParams['font.sans-serif'] = ['DejaVu Sans']
# rcParams['font.monospace'] = ['DejaVu Sans Mono']
## libertinus does not work
rcParams["font.family"] = "Libertinus Serif"
rcParams["font.sans-serif"] = ["Libertinus Sans"]
rcParams["font.monospace"] = ["Libertinus Mono"]
# Path to your local font directory
local_font_path = os.getenv("HOME") + "/.local/share/fonts/Libertinus"
# Add your local font directory to the font manager
font_dirs = [local_font_path]
font_files = font_manager.findSystemFonts(fontpaths=font_dirs, fontext="otf")
for font_file in font_files:
    font_manager.fontManager.addfont(font_file)


try:
    Path("./output/").mkdir(parents=True)
except FileExistsError:
    pass


TEX_CONSTANTS = r"""% autogenerated by plot.py - do not edit
{}
"""


def _dump_yaml(fd, tex):
    def float_representer(dumper, value):
        return dumper.represent_scalar(
            "tag:yaml.org,2002:float", "{:.8f}".format(value)
        )

    yaml.add_representer(float, float_representer)
    for key, value in tex.items():
        if type(value) is np.float64:
            tex[key] = float(value)
    yaml.safe_dump(tex, fd)


def make_tex_constants(tex, precision=None):

    def new_command_tex_float(key, value, precision=None):
        key = key[0].upper() + key[1:]
        return r"\newcommand{{\py{}}}{{{}}}".format(key, value)

    # pp(tex)
    print("constants:")
    for key, value in tex.items():
        print(f" - {key} = {value} (type={type(value)})")
    with open("./output/constants.tex", "w") as fd:
        cs = []
        for key, value in tex.items():
            cs.append(new_command_tex_float(key, value, precision))
        fmt = "\n".join(cs)
        fd.write(TEX_CONSTANTS.format(fmt))
    with open("./output/constants.yml", "w") as fd:
        _dump_yaml(fd, tex)


PLOT_PAD = 1.08
SIZE_SINGLE_PLOT = 4
# size: 2x2 plots
SIZE_2x2 = (2 * SIZE_SINGLE_PLOT, 2 * SIZE_SINGLE_PLOT)
SIZE_2x1 = (2 * SIZE_SINGLE_PLOT, SIZE_SINGLE_PLOT)

tex = {}


def analyze_ot_with_sinkhorn(xs, xt, SCALE):
    sinkhorn, sinkhorn_meta = solver.solve_ot_with_sinkhorn(xs, xt, SCALE=SCALE)

    def plot_ot(meta, xs, xt, solution, file=""):
        # rows and columns
        r, c = 2, 2
        plt.figure(figsize=SIZE_2x2)
        # Plot 1: Distributions
        plt.subplot(r, c, 1)
        plt.plot(xs[:, 0], xs[:, 1], "+b", label="Source samples")
        plt.plot(xt[:, 0], xt[:, 1], "xr", label="Target samples")
        plt.xlabel("x / 1")
        plt.ylabel("y / 1")
        plt.legend(loc=0)
        plt.title(f"Source and target distributions")
        # Plot 2: Cost matrix M
        plt.subplot(r, c, 2)
        plt.imshow(meta["loss"], interpolation="nearest")
        plt.xlabel("Index of source / 1")
        plt.ylabel("Index of target / 1")
        plt.title(f"Cost matrix M")
        # Plot 3: OT matrix `solution`
        plt.subplot(r, c, 3)
        plt.imshow(solution, interpolation="nearest")
        plt.xlabel("Index of source / 1")
        plt.ylabel("Index of target / 1")
        plt.title(f"Transport plan: sinkhorn")
        # Plot 4: OT matrix `solution` with samples
        plt.subplot(r, c, 4)
        ot.plot.plot2D_samples_mat(xs, xt, solution, color=[0.5, 0.5, 1])
        plt.plot(xs[:, 0], xs[:, 1], "+b", label="Source samples")
        plt.plot(xt[:, 0], xt[:, 1], "xr", label="Target samples")
        plt.xlabel("x / 1")
        plt.ylabel("y / 1")
        plt.legend(loc=0)
        plt.title(f"Transport plan: sinkhorn with samples")
        plt.tight_layout(pad=PLOT_PAD)
        plt.savefig(file)
        plt.clf()

    plot_ot(sinkhorn_meta, xs, xt, sinkhorn, file="output/sinkhorn-solution.svg")
    return sinkhorn


# def analyze_hyperparameters(xs, xt):
#    """Runs hyperparameter optimization.
#
#    Returns
#    -------
#    config: dict    The optimal config dictionary for the ABM OT solver.
#    """
#
#    def loss_from_dist(xs, xt, M_solution):
#        M_cost = ot.dist(xs, xt)
#        return solver.loss(M_cost, M_solution)
#
#
#    def objective(trial):
#        config = dict(
#            n_humans=trial.suggest_int("n_humans", 10, 200, step=10),
#            seed=42,
#            resource_restoration_ticks=trial.suggest_int(
#                "resource_restoration_ticks", 1, 100, step=5
#            ),
#            hunger_starved_to_death=trial.suggest_int(
#                "hunger_starved_to_death", 10, 1000, step=30
#            ),
#            n_humans_crowded=2,  # trial.suggest_int("n_humans_crowded", 2, 30),
#            steps=trial.suggest_int("steps", 500, 3000, step=500),
#            target_resource_amount=1,
#            resource_depleted_after_collections=trial.suggest_int(
#                "resource_depleted_after_collections", 1, 10, step=1
#            ),
#        )
#        abm, abm_meta = solver.solve_ot_with_abm(xs, xt, **config)
#        abm = util.doubly_stochastic(abm)
#        if (abm == 0.0).all():
#            return math.inf
#        comparison = solver.compare(xs, xt, abm, sinkhorn)
#        solver.plot_abm(abm_meta, xs, xt, abm, config, comparison)
#        return loss_from_dist(xs, xt, abm)
#
#
#    study = optuna.create_study(direction="minimize", storage="sqlite:///data/hyperparam-optimization.sqlite", load_if_exists=True)
#    print(f"Sampler is {study.sampler.__class__.__name__}")


def optimal_parameter_metrics(xs, xt, conf, sinkhorn):
    abm, abm_meta = solver.solve_ot_with_abm(xs, xt, **conf)
    abm = util.doubly_stochastic(abm)
    result = solver.compare(xs, xt, abm, sinkhorn)
    diff = (result.loss_abm - result.loss_ot) / result.loss_ot * 100
    tex["OptimalSolutionDiff"] = round(diff, 2)
    plt.figure(figsize=SIZE_2x1)
    # Plot 1: OT matrix `abm`
    plt.subplot(1, 2, 1)
    plt.imshow(abm, interpolation="nearest")
    plt.xlabel("Index of source / 1")
    plt.ylabel("Index of target / 1")
    plt.title(f"Transport plan: sinkhorn")
    # Plot 2: OT matrix `abm` with samples
    plt.subplot(1, 2, 2)
    ot.plot.plot2D_samples_mat(xs, xt, abm, color=[0.5, 0.5, 1])
    plt.plot(xs[:, 0], xs[:, 1], "+b", label="Source samples")
    plt.plot(xt[:, 0], xt[:, 1], "xr", label="Target samples")
    plt.xlabel("x / 1")
    plt.ylabel("y / 1")
    plt.legend(loc=0)
    plt.title(f"Transport plan: sinkhorn with samples")
    plt.tight_layout(pad=PLOT_PAD)
    plt.savefig("output/abm-hyperparam-optim-result-solution.svg")
    plt.clf()



def analyze_optimality(conf, SCALE):
    diffs = []
    tex["OptimalityDifferentSamples"] = 20
    for _ in range(tex["OptimalityDifferentSamples"]):
        xs, xt = solver.generate_distributions(SCALE=SCALE)
        sinkhorn, sinkhorn_meta = solver.solve_ot_with_sinkhorn(xs, xt, SCALE=SCALE)
        abm, abm_meta = solver.solve_ot_with_abm(xs, xt, **conf)
        abm = util.doubly_stochastic(abm)
        result = solver.compare(xs, xt, abm, sinkhorn)
        diff = (result.loss_abm - result.loss_ot) / result.loss_ot * 100
        diffs.append(diff)
    mean = np.mean(diffs)
    tex["OptimalityMean"] = mean
    std = np.std(diffs)
    tex["OptimalityStd"] = std
    print(f" - diff = ({mean} +- {std})% from sinkhorn solution")


def analyze_convergence(xs, xt, sinkhorn, input_config):
    steps = 6000
    tex["ConvergenceStepsTotal"] = steps
    steps_per_plot = 1000

    config = input_config.copy()
    config["steps"] = steps
    config["hunger_starved_to_death"] = steps # no human should die here

    N_plots = int(steps / steps_per_plot)
    if N_plots % 2 != 0:
        raise RuntimeError(
            f"should pick an even number of step intervals to analyze steps/steps_per_plot = {steps}/{steps_per_plot} = {N_plots}"
        )

    abm, abm_meta = solver.solve_ot_with_abm(xs, xt, **config)
    abm = util.doubly_stochastic(abm)
    _comparison = solver.compare(xs, xt, abm, sinkhorn)

    # plot the whole thing
    plt.figure(figsize=SIZE_2x1)  # Adjust the figure size as needed
    # Plot 1: Cost matrix M
    plt.subplot(1, 2, 1)
    plt.imshow(abm, interpolation="nearest")
    plt.xlabel("Index of source / 1")
    plt.ylabel("Index of target / 1")
    plt.title(f"OT matrix: All {steps} steps.")
    # Plot 2: Visualized results of OT solution
    plt.subplot(1, 2, 2)
    ot.plot.plot2D_samples_mat(xs, xt, abm, color=[0.5, 0.5, 1])
    plt.plot(xs[:, 0], xs[:, 1], "+b", label="Source samples")
    plt.plot(xt[:, 0], xt[:, 1], "xr", label="Target samples")
    plt.xlabel("x / 1")
    plt.ylabel("y / 1")
    plt.legend(loc=0)
    plt.title(f"OT solution with sample ditributions: All {steps} steps.")
    plt.tight_layout(pad=PLOT_PAD)
    plt.savefig("output/abm-convergence-full.svg")
    plt.clf()

    # Plot convergence
    SIZE_Nx2 = (4 * SIZE_SINGLE_PLOT, (N_plots * SIZE_SINGLE_PLOT) // 2)
    plt.figure(figsize=SIZE_Nx2)  # Adjust the figure size as needed
    conv_loss = []
    conv_loss_diff = []
    for n in range(N_plots):
        i, j = n * 1000, (n + 1) * 1000
        all_resources = abm_meta["collected_resources"]
        collected_resources = all_resources[
            (all_resources[:, 0] > i) & (all_resources[:, 0] < j)
        ]
        partial = util.collected_resource_list_to_cost_matrix(
            collected_resources[:, 1:], xs, xt
        )
        partial = util.doubly_stochastic(partial)
        result = solver.compare(xs, xt, partial, sinkhorn)
        loss = result.loss_abm
        tex["ConvergenceLoss" + "i" * n] = round(loss, 2)
        conv_loss.append(loss)
        loss_diff = (tex["ConvergenceLoss" + "i" * n] - result.loss_ot) / result.loss_ot * 100
        tex["ConvergenceLossDiff" + "i" * n] = round(loss_diff, 2)
        conv_loss_diff.append(loss_diff)
        partial_meta = {
            "paths": abm_meta["paths"],
            "alive_humans": abm_meta["alive_humans"][i:j],
            "avg_resources": abm_meta["avg_resources"][i:j],
            "constants": abm_meta["constants"],
            "collected_resources": collected_resources,
        }
        # Plot 1: Cost matrix M
        plt.subplot(N_plots // 2, 4, (2 * n) + 1)
        plt.imshow(abm, interpolation="nearest")
        print(f" - analysis of [{i}-{j}) steps")
        plt.title(f"[{i}-{j})")
        # plt.title(f"OT matrix: [{i}-{j}) steps,")
        # Plot 2: Visualized results of OT solution
        plt.subplot(N_plots // 2, 4, (2 * n) + 2)
        ot.plot.plot2D_samples_mat(xs, xt, abm, color=[0.5, 0.5, 1])
        plt.plot(xs[:, 0], xs[:, 1], "+b", label="Source samples")
        plt.plot(xt[:, 0], xt[:, 1], "xr", label="Target samples")
        plt.legend(loc=0)
        # plt.title(f"OT solution with sample ditributions.")
    plt.tight_layout(pad=PLOT_PAD)
    plt.savefig("output/abm-convergence-parts.svg")
    plt.clf()
    with open("output/abm-convergence-parts.pickle", "wb") as fd:
        pickle.dump({"conv_loss": conv_loss, "conv_loss_diff": conv_loss_diff}, fd)


def analyze_optimality2(trialdb, SCALE, N_tests=5, M_top=5):
    study = optuna.load_study(study_name="ABM", storage=trialdb)
    def top(study, n: int):
        return sorted(
            study.trials, key=lambda x: x.value if x.value is not None else math.inf
        )[:n]

    data = []
    for i in range(N_tests):
        xs, xt = solver.generate_distributions(SCALE=SCALE)
        data.append([])
        for trial in top(study, M_top):
            conf = trial.params
            conf["seed"] = 42
            sinkhorn, sinkhorn_meta = solver.solve_ot_with_sinkhorn(xs, xt, SCALE=SCALE)
            abm, abm_meta = solver.solve_ot_with_abm(xs, xt, **conf)
            abm = util.doubly_stochastic(abm)
            result = solver.compare(xs, xt, abm, sinkhorn)
            diff = (result.loss_abm - result.loss_ot) / result.loss_ot * 100
            data[-1].append(diff)
    diffs, stds = np.mean(data, axis=0), np.std(data, axis=0)
    table = (r" \\ ".join([r"${:.2f} \pm {:.2f}$"] * len(diffs))).format(*np.array([[i,j] for i,j in zip(diffs, stds)]).flatten())
    tex["OptimalityTableM"] = M_top
    tex["OptimalityTableN"] = N_tests
    tex["OptimalityTableOfMTopTrialParamsForNTests"] = table
    return diffs, stds, table


if __name__ == "__main__":
    SCALE = 5
    tex["DistributionScale"] = SCALE
    xs, xt = solver.generate_distributions(SCALE=SCALE)

    print(f"sinkhorn plot")
    sinkhorn = analyze_ot_with_sinkhorn(xs, xt, SCALE)

    # old:
    #hyperparam_optimization_results = {
    #    "n_humans": 150,
    #    "use_last_only": True,
    #    "resource_restoration_ticks": 46,
    #    "hunger_starved_to_death": 610,
    #    # "steps": 3000,
    #    "resource_depleted_after_collections": 2,
    #}
    #hyperparam_optimization_results["n_humans_crowded"] = 2
    optunadb = "sqlite:///src/hyperparam-optimization-ipynb-2.sqlite"
    study = optuna.load_study(study_name="ABM", storage=optunadb)
    hyperparam_optimization_results = study.best_params
    hyperparam_optimization_results["seed"] = 2
    for key, value in hyperparam_optimization_results.items():
        tex[key.replace("_", "")] = value
    optimal_parameter_metrics(xs, xt, hyperparam_optimization_results, sinkhorn)

    print(f"optimality: top hyperparams")
    analyze_optimality2(optunadb, 5, N_tests=5, M_top=5)

    print(f"optimality: comparison with sinkhorn")
    analyze_optimality(hyperparam_optimization_results, SCALE)

    print(f"convergence of abm")
    analyze_convergence(xs, xt, sinkhorn, hyperparam_optimization_results)

    make_tex_constants(tex)
